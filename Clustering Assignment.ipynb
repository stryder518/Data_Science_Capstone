{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: BeautifulSoup4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.7.1)\nRequirement already satisfied: soupsieve>=1.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from BeautifulSoup4) (1.7.1)\nSolving environment: / ^C\nfailed\n\nCondaError: KeyboardInterrupt\n\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - folium=0.5.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    folium-0.5.0               |             py_0          45 KB  conda-forge\n    altair-4.1.0               |             py_1         614 KB  conda-forge\n    branca-0.4.1               |             py_0          26 KB  conda-forge\n    vincent-0.4.4              |             py_1          28 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         713 KB\n\nThe following NEW packages will be INSTALLED:\n\n    altair:  4.1.0-py_1 conda-forge\n    branca:  0.4.1-py_0 conda-forge\n    folium:  0.5.0-py_0 conda-forge\n    vincent: 0.4.4-py_1 conda-forge\n\n\nDownloading and Extracting Packages\nfolium-0.5.0         | 45 KB     | ##################################### | 100% \naltair-4.1.0         | 614 KB    | ##################################### | 100% \nbranca-0.4.1         | 26 KB     | ##################################### | 100% \nvincent-0.4.4        | 28 KB     | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nRequirement already satisfied: html5lib in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.0.1)\nRequirement already satisfied: webencodings in /opt/conda/envs/Python36/lib/python3.6/site-packages (from html5lib) (0.5.1)\nRequirement already satisfied: six>=1.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from html5lib) (1.12.0)\nRequirement already satisfied: lxml in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.3.1)\nRequirement already satisfied: et_xmlfile in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.0.1)\nLibraries imported.\n"
                }
            ],
            "source": "import numpy as np # library to handle data in a vectorized manner\n\n!pip install BeautifulSoup4\nfrom bs4 import BeautifulSoup\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nimport urllib.request\n\n!pip install html5lib\n!pip install lxml\n!pip install et_xmlfile\n\nfrom pandas import DataFrame\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "url = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M' #URL we're trying to get data from. \npage = urllib.request.urlopen(url) #open the URL put it into a string variable named page. call thsi wahtever."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "soup = BeautifulSoup(page, \"html5lib\")\n#print(soup.prettify())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "tables = soup.find_all(\"table\")"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'soup' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-4-d623853f1f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzip_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wikitable sortable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcol1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcol2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcol3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
                    ]
                }
            ],
            "source": "zip_table = soup.find('table', class_='wikitable sortable')\n\ncol1 = []\ncol2 = []\ncol3 = []\n\nfor row in zip_table.findAll('tr'):\n    cells = row.findAll('td')\n    \n    if len(cells) == 3: #if the length of the number of cells (total columns ='s three')\n        col1.append(cells[0].find(text=True)) #find column 1 text\n        col2.append(cells[1].find(text=True)) #find column 2 text\n        col3.append(cells[2].find(text=True)) #find column 3 text\n        \n\nzipDF = pd.DataFrame(col1, columns = ['postal_code']) #setup a new dataframe\n\nzipDF['Borough'] = col2 #set column borough to equal column 2 from the table. \n\nzipDF['Neighborhood'] = col3 #set column neighborhood to col 3 from the html parsed table. \n\n#clena out new line garbage. \n\nzipDF = zipDF.replace('\\\\n','', regex=True) \n\nhoodDF = zipDF.Neighborhood.str.split(\",\",expand=True)\n\nzipDF[\"hood1\"]= hoodDF[0]\nzipDF[\"hood2\"]= hoodDF[1]\nzipDF[\"hood3\"]= hoodDF[2]\nzipDF[\"hood4\"]= hoodDF[3]\nzipDF[\"hood5\"]= hoodDF[4]\nzipDF[\"hood6\"]= hoodDF[5]\nzipDF[\"hood7\"]= hoodDF[6]\nzipDF[\"hood8\"]= hoodDF[7]\n\nzipDF.drop(['Neighborhood'], axis = 1, inplace = True)\n\n#copy columns\n\n\njoinDF = zipDF.copy() #new dataframe equal to zipDF\njoinDF2 = zipDF.copy()  #second new dataframe equal to zipDF\njoinDF3 = zipDF.copy()\njoinDF4 = zipDF.copy()\njoinDF5 = zipDF.copy()\njoinDF6 = zipDF.copy()\njoinDF7 = zipDF.copy()\njoinDF8 = zipDF.copy()\n\njoinDF.drop(['hood2', 'hood3', 'hood4', 'hood5','hood6','hood7', 'hood8'], axis = 1, inplace = True) #keep only hood1\njoinDF2.drop(['hood1', 'hood3', 'hood4', 'hood5','hood6','hood7', 'hood8'], axis = 1, inplace = True) #keep only hood 2\njoinDF3.drop(['hood1', 'hood2', 'hood4', 'hood5','hood6','hood7', 'hood8'], axis = 1, inplace = True) #keep only hood 3\njoinDF4.drop(['hood1', 'hood2', 'hood3', 'hood5','hood6','hood7', 'hood8'], axis = 1, inplace = True) #keep only hood 4\njoinDF5.drop(['hood1', 'hood2', 'hood3', 'hood4','hood6','hood7', 'hood8'], axis = 1, inplace = True) #keep only hood 5\njoinDF6.drop(['hood1', 'hood2', 'hood3', 'hood4','hood5','hood7', 'hood8'], axis = 1, inplace = True) #keep only hood 6\njoinDF7.drop(['hood1', 'hood2', 'hood3', 'hood4','hood5','hood6', 'hood8'], axis = 1, inplace = True) #keep only hood 7\njoinDF8.drop(['hood1', 'hood2', 'hood3', 'hood4','hood5','hood6', 'hood7'], axis = 1, inplace = True) #keep only hood 8\n\n#^ This could have all been done in a for loop- but i'm lazy. :(\n\njoinedDF = zipDF.copy() #initialize joined DF to equal the first DF. \n\ndf_array = [joinDF, joinDF2, joinDF3, joinDF4, joinDF5, joinDF6, joinDF7, joinDF8] #will use this to pass dataframes into the join function. \n\n#instantiate allHoods Dataframe\nallHoodsDF = pd.DataFrame()\n\n#this for loop loops through the array of dataframes to transform and join them into a single huge dataframe. \nfor i in range(0,7):\n    allHoodsDF = joinFrames(allHoodsDF, df_array[i])\n\nallHoodsDF.rename(columns={ allHoodsDF.columns[2]: \"Neighborhood\" }, inplace = True)\n\n# drop neighborhoods that are not assigned. \nallHoodsDF = allHoodsDF.drop(allHoodsDF[(allHoodsDF.Borough == \"Not assigned\")].index)\n#replace not assigned with borough names. \nallHoodsDF.Neighborhood.replace(\"Not assigned\", allHoodsDF.Borough, inplace=True)\n\n#clean up empties. \nallHoodsDF.Neighborhood.fillna(allHoodsDF.Borough, inplace=True)\n# drop duplicate rows:\nallHoodsDF=allHoodsDF.drop_duplicates()\n\n#allHoodsDF.shape\n#allHoodsDF.head(4)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Add Lat Long\nlatlong= pd.read_csv(\"http://cocl.us/Geospatial_data\")\nlatlong.rename(columns={'Postal Code':'postal_code'}, inplace=True)\nlatlong.set_index(\"postal_code\")\nlatlong.set_index(\"postal_code\")\n#latlong.head(3)\ntdotDF=pd.merge(allHoodsDF, latlong)\ntdotDF.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def joinFrames(joinedDF, newDF):\n        temp = newDF.copy()\n        temp.rename(columns={ dfIn.columns[2]: \"3\" }, inplace = True)\n        joinedDF = pd.concat([joinedDF, newDF]) #update the joined DF to join the new information. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}